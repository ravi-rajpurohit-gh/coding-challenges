# coding-challenges

# MissionWired Task

## Data Engineering Problem

Here’s a well-structured `README.md` file for your project:

---

# MissionWired Data Engineering Task

## Overview

This project is a data engineering task involving working with several datasets related to CRM data, performing data transformation, and producing output files for further analysis.

I have used both **Pandas** and **PySpark** to showcase my versatility in handling data at different scales, ensuring the code can be applied in both local and distributed environments.

## Features

- **Data Ingestion**: Loading and processing CSV data from public AWS S3 buckets.
- **Data Transformation**: Merging datasets, filtering records, and handling missing values.
- **Output Generation**: Producing two key output files:
  1. `people.csv` – A file with key attributes like email, source code, and subscription status.
  2. `acquisition_facts.csv` – A file that aggregates the number of acquisitions by date.
- **Bonus Enhancements**:
  - Utilized PySpark for large-scale processing in addition to Pandas.
  - Added data visualization and analysis for deeper insights.

## Technologies Used

- **Python**: Core language for the task.
- **Pandas**: Used for data processing in the local environment.
- **PySpark**: Used to handle larger datasets in a distributed fashion.
- **Google Colab**: Interactive notebook environment for development.

## Files

- **MissionWiredDataEngineerTask.ipynb**: The main notebook file that includes both the Pandas and PySpark approaches, complete with code and documentation.
- **people.csv**: Output file containing constituent information, created in the process.
- **acquisition_facts.csv**: Output file with aggregated acquisition data.

## How to Run

1. Clone the repository. Branch - missionWiredTask
2. Open `MissionWiredDataEngineerTask.ipynb` in Google Colab or Jupyter Notebook.
3. Run the cells to execute the data processing and output generation steps.

## Conclusion

This project was an enjoyable and insightful experience, allowing me to demonstrate my data engineering skills while going beyond the original requirements to showcase additional abilities in distributed data processing and visualization.

### Contact me - ravirajpurohit414@gmail.com
